This is a summary of the current state of the project:

The project is a Rust implementation of a Prolog interpreter based on the Warren Abstract Machine (WAM). The code is organized into two main modules: parser and wam. The parser module is responsible for parsing Prolog source code, while the wam module handles the execution of Prolog programs using the WAM architecture.

The parser module consists of the following files:

    ast.rs: Contains the definition of the abstract syntax tree (AST) for Prolog terms and clauses.
    lexer.rs: Contains the lexer implementation responsible for tokenizing Prolog source code.
    mod.rs: Contains the parser implementation responsible for parsing Prolog tokens into an AST.

The wam module consists of the following files:

    data_structures.rs: Contains the definition of data structures used in the WAM, such as the heap, the stack, and the trail.
    mod.rs: Contains the WamEmulator struct and its implementation, which represents the WAM state and provides methods for executing Prolog programs.

The lib.rs file is the main entry point of the application, where the main function is defined. Currently, the main function creates a simple Term object, pushes it onto the heap of a new WamEmulator instance, and prints the index where the term was pushed.

During the previous session, we have implemented and tested the parser to handle basic Prolog programs. We have also discussed adding support for parsing rule bodies with disjunctions, but have not yet incorporated the changes into the existing codebase.

Now I will list all the source code modules except ast.rs which I will send in a separate request to avoid
going over the request size limit.

Please read these source code listings and remember them by file name for further requets. Let me know when you are done reading and
I will send src/ast.rc.

// src/main.rs
use prolog_wam_compiler::{WamEmulator, Term};

fn main() {
    let term = Term::Atom("example".to_string());

    let mut emulator = WamEmulator::new();
    let index = emulator.push_term(&term);

    println!("Term pushed to heap at index: {}", index);
}
// src/lib.rs
pub mod wam;
pub mod parser;

pub use wam::{WamEmulator, Term, HeapCell};
pub use parser::lexer;

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_skip_whitespace() {
        println!("Starting test_skip_whitespace");
        let input = "   some text";
        let result = lexer::skip_whitespace(input);
        assert_eq!(result, "some text");
        println!("Ending test_skip_whitespace");
    }
}


// src/wam/mod.rs
pub mod data_structures;

pub use data_structures::{WamEmulator, Term, HeapCell};

src/wam/data_structures.rs
pub enum Term {
    Atom(String),
    Compound(String, Vec<Term>),
    Variable,
}

#[derive(Debug, PartialEq)]
pub enum HeapCell {
    Reference(usize),
    Structure(String, Vec<usize>),
    Constant(String),
}

pub struct WamEmulator {
    heap: Vec<HeapCell>,
}

impl WamEmulator {
    pub fn new() -> Self {
        Self { heap: Vec::new() }
    }

    pub fn push_term(&mut self, term: &Term) -> usize {
        match term {
            Term::Atom(name) => {
                let index = self.heap.len();
                self.heap.push(HeapCell::Constant(name.clone()));
                index
            }
            Term::Compound(_, _) => {
                // Implement compound term storage here
                unimplemented!()
            }
            Term::Variable => {
                let index = self.heap.len();
                self.heap.push(HeapCell::Reference(index));
                index
            }
        }
    }

    pub fn get_heap_cell(&self, index: usize) -> Option<&HeapCell> {
        self.heap.get(index)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_push_atom() {
        println!("Starting test_push_atom");
        let term = Term::Atom("example".to_string());
        let mut emulator = WamEmulator::new();
        let index = emulator.push_term(&term);
        let cell = emulator.get_heap_cell(index).unwrap();

        assert_eq!(cell, &HeapCell::Constant("example".to_string()));
        println!("Ending test_push_atom");
    }
}

// mod.rs
pub mod ast;
pub mod lexer;

This is a summary of the current state of the project:

The project is a Rust implementation of a Prolog interpreter based on the Warren Abstract Machine (WAM). The code is organized into two main modules: parser and wam. The parser module is responsible for parsing Prolog source code, while the wam module handles the execution of Prolog programs using the WAM architecture.

The parser module consists of the following files:

    ast.rs: Contains the definition of the abstract syntax tree (AST) for Prolog terms and clauses.
    lexer.rs: Contains the lexer implementation responsible for tokenizing Prolog source code.
    mod.rs: Contains the parser implementation responsible for parsing Prolog tokens into an AST.

The wam module consists of the following files:

    data_structures.rs: Contains the definition of data structures used in the WAM, such as the heap, the stack, and the trail.
    mod.rs: Contains the WamEmulator struct and its implementation, which represents the WAM state and provides methods for executing Prolog programs.

The lib.rs file is the main entry point of the application, where the main function is defined. Currently, the main function creates a simple Term object, pushes it onto the heap of a new WamEmulator instance, and prints the index where the term was pushed.

During the previous session, we have implemented and tested the parser to handle basic Prolog programs. We have also discussed adding support for parsing rule bodies with disjunctions, but have not yet incorporated the changes into the existing codebase.

Now I will list all the source code modules except lexer.rs which I will send in a separate request to avoid
going over the request size limit.

// src/main.rs
use prolog_wam_compiler::{WamEmulator, Term};

fn main() {
    let term = Term::Atom("example".to_string());

    let mut emulator = WamEmulator::new();
    let index = emulator.push_term(&term);

    println!("Term pushed to heap at index: {}", index);
}
// src/lib.rs
pub mod wam;
pub mod parser;

pub use wam::{WamEmulator, Term, HeapCell};
pub use parser::lexer;

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_skip_whitespace() {
        println!("Starting test_skip_whitespace");
        let input = "   some text";
        let result = lexer::skip_whitespace(input);
        assert_eq!(result, "some text");
        println!("Ending test_skip_whitespace");
    }
}


// src/wam/mod.rs
pub mod data_structures;

pub use data_structures::{WamEmulator, Term, HeapCell};

src/wam/data_structures.rs
pub enum Term {
    Atom(String),
    Compound(String, Vec<Term>),
    Variable,
}

#[derive(Debug, PartialEq)]
pub enum HeapCell {
    Reference(usize),
    Structure(String, Vec<usize>),
    Constant(String),
}

pub struct WamEmulator {
    heap: Vec<HeapCell>,
}

impl WamEmulator {
    pub fn new() -> Self {
        Self { heap: Vec::new() }
    }

    pub fn push_term(&mut self, term: &Term) -> usize {
        match term {
            Term::Atom(name) => {
                let index = self.heap.len();
                self.heap.push(HeapCell::Constant(name.clone()));
                index
            }
            Term::Compound(_, _) => {
                // Implement compound term storage here
                unimplemented!()
            }
            Term::Variable => {
                let index = self.heap.len();
                self.heap.push(HeapCell::Reference(index));
                index
            }
        }
    }

    pub fn get_heap_cell(&self, index: usize) -> Option<&HeapCell> {
        self.heap.get(index)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_push_atom() {
        println!("Starting test_push_atom");
        let term = Term::Atom("example".to_string());
        let mut emulator = WamEmulator::new();
        let index = emulator.push_term(&term);
        let cell = emulator.get_heap_cell(index).unwrap();

        assert_eq!(cell, &HeapCell::Constant("example".to_string()));
        println!("Ending test_push_atom");
    }
}

// mod.rs
pub mod ast;
pub mod lexer;




// src/parser/lexer.rs
use std::iter::Peekable;

fn parse_atom_or_variable<I: Iterator<Item = char>>(first_char: char, iter: &mut Peekable<I>) -> Result<Token, LexerError> {
    let mut name = String::new();
    name.push(first_char);

    while let Some(&c) = iter.peek() {
        match c {
            'A'..='Z' | 'a'..='z' | '0'..='9' | '_' => {
                name.push(c);
                iter.next();
            }
            _ => break,
        }
    }

    let token = if name.chars().next().unwrap().is_uppercase() || name.starts_with('_') {
        Token::Variable(name)
    } else {
        Token::Atom(name)
    };

    Ok(token)
}

fn parse_integer<I: Iterator<Item = char>>(first_digit: char, iter: &mut Peekable<I>) -> Result<Token, LexerError> {
    let mut value = String::new();
    value.push(first_digit);

    while let Some(&c) = iter.peek() {
        if c.is_digit(10) {
            value.push(c);
            iter.next();
        } else {
            break;
        }
    }

    if value.is_empty() {
        return Err(LexerError::InvalidInteger(value));
    }

    value
        .parse::<i64>()
        .map(Token::Number)
        .map_err(|_| LexerError::InvalidInteger(value))
}

pub fn skip_whitespace(input: &str) -> &str {
    input.trim_start()
}

pub fn tokenize(input: &str) -> Result<Vec<Token>, LexerError> {
    let mut tokens = Vec::new();
    let mut iter = input.chars().peekable();

    while let Some(&c) = iter.peek() {
        println!("DEBUG: Current character: {:?}", c);
    
        match c {
            ' ' | '\t' | '\n' | '\r' => {
                iter.next(); // skip whitespace
            }
            ',' => {
                iter.next();
                tokens.push(Token::Comma);
                while let Some(&c) = iter.peek() {
                    if c == ' ' || c == ',' {
                        iter.next();
                    } else {
                        break;
                    }
                }
            }
            'A'..='Z' | 'a'..='z' | '_' => {
                let first_char = iter.next().unwrap();
                tokens.push(parse_atom_or_variable(first_char, &mut iter)?);
            }
            '0'..='9' => {
                let first_digit = iter.next().unwrap();
                tokens.push(parse_integer(first_digit, &mut iter)?);
            }
            '(' => {
                iter.next();
                tokens.push(Token::LParen);
            }
            ')' => {
                iter.next();
                tokens.push(Token::RParen);
            }
            '.' => {
                iter.next();
                tokens.push(Token::Dot);
            }
            ':' => {
                iter.next();
                if let Some(&'-') = iter.peek() {
                    iter.next();
                    tokens.push(Token::If);
                } else {
                    return Err(LexerError::UnexpectedChar(c));
                }
            }
            ';' => {
                iter.next();
                tokens.push(Token::And);
            }
            '[' => {
                iter.next();
                tokens.push(Token::LBracket);
            }
            ']' => {
                iter.next();
                tokens.push(Token::RBracket);
            }
            _ => {
                iter.next();
                if c.is_whitespace() {
                } else {
                    return Err(LexerError::UnexpectedChar(c));
                }
            }
        }
    }

    println!("DEBUG: Final tokens: {:?}", tokens);
    Ok(tokens)
}

#[derive(Debug, PartialEq, Clone)]
pub enum Token {
    Atom(String),
    Variable(String),
    Number(i64),
    LParen,
    RParen,
    LBracket,
    RBracket,
    Comma,
    Dot,
    If,
    And,
}

#[derive(Debug)]
pub enum LexerError {
    UnexpectedChar(char),
    InvalidInteger(String),
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_token_enum() {
        println!("Starting test_token_enum");
        let atom = Token::Atom("likes".to_string());
        let variable = Token::Variable("X".to_string());
        let left_paren = Token::LParen;
        let right_paren = Token::RParen;
        let comma = Token::Comma;
        let dot = Token::Dot;

        assert_eq!(atom, Token::Atom("likes".to_string()));
        assert_eq!(variable, Token::Variable("X".to_string()));
        assert_eq!(left_paren, Token::LParen);
        assert_eq!(right_paren, Token::RParen);
        assert_eq!(comma, Token::Comma);
        assert_eq!(dot, Token::Dot);
        println!("Ending test_token_enum");
    }

    #[test]
    fn test_tokenize_atoms_and_variables() {
        println!("Starting test_tokenize_atoms_and_variables");
        let input = "likes(X, food).";
        let expected_tokens = vec![
            Token::Atom("likes".to_string()),
            Token::LParen,
            Token::Variable("X".to_string()),
            Token::Comma,
            Token::Atom("food".to_string()),
            Token::RParen,
            Token::Dot,
        ];
    
        let tokens = tokenize(input).unwrap();
        assert_eq!(tokens, expected_tokens);
        println!("Ending test_tokenize_atoms_and_variables");
    }
}
