// src/parser/ast.rs
use crate::parser::lexer::{tokenize, Token};

#[derive(PartialEq, Debug, Clone)]
pub struct Clause {
    pub head: Term,
    pub body: Vec<Term>,
}

pub enum Term {
    Atom(String),
    Variable(String),
    Structure {
        functor: String,
        arity: usize,
        args: Vec<Term>,
    },
    List(Vec<Term>),
    Number(i64),
}

pub type ParseResult<T> = Result<T, ParseError>;

pub fn parse(input: &str) -> ParseResult<Vec<Clause>> {
    let tokens = tokenize(input)?;
    println!("Tokens: {:?}", tokens); // Debug output added here
    let mut clauses = Vec::new();

    let mut remaining_tokens = &tokens[..];
    while !remaining_tokens.is_empty() {
        let (head, rest) = parse_term(remaining_tokens)?;
        remaining_tokens = rest;

        let body = if let Ok(new_remaining_tokens) = expect_token(Token::If, remaining_tokens) {
            remaining_tokens = new_remaining_tokens;
            let mut body_terms = Vec::new();

            while let Ok((term, new_remaining_tokens)) = parse_term(remaining_tokens) {
                remaining_tokens = new_remaining_tokens;
                body_terms.push(term);

                // Change this part
                if let Ok(new_remaining_tokens) = expect_token(Token::And, remaining_tokens)
                    .or(expect_token(Token::Comma, remaining_tokens))
                {
                    remaining_tokens = new_remaining_tokens;
                } else {
                    break;
                }
            }

            body_terms
        } else {
            Vec::new()
        };

        println!("Head: {:?}, Body: {:?}", head, body); // Debug output added here

        remaining_tokens = expect_token(Token::Dot, remaining_tokens)?;
        clauses.push(Clause { head, body });
    }

    Ok(clauses)
}

#[derive(Debug)]
pub enum ParseError {
    LexerError(crate::parser::lexer::LexerError),
    UnexpectedToken(Token),
    UnexpectedEndOfInput,
    InvalidToken,
    // Other error variants will be added as needed
}

// This allows us to convert LexerError into ParseError
impl From<crate::parser::lexer::LexerError> for ParseError {
    fn from(error: crate::parser::lexer::LexerError) -> Self {
        ParseError::LexerError(error)
    }
}

fn expect_token<'a>(expected: Token, tokens: &'a [Token]) -> ParseResult<&'a [Token]> {
    if let Some(token) = tokens.first() {
        if *token == expected {
            Ok(&tokens[1..])
        } else {
            Err(ParseError::UnexpectedToken(token.clone()))
        }
    } else {
        Err(ParseError::UnexpectedEndOfInput)
    }
}

fn parse_term<'a>(tokens: &'a [Token]) -> ParseResult<(Term, &'a [Token])> {
    println!("parse_term: {:?}", tokens);
    let (token, rest) = expect_any_token(tokens)?;
    match token {
        Token::Atom(atom) => {
            let (next_token, next_rest) = expect_any_token(rest)?;
            if next_token == Token::LParen {
                let mut args = Vec::new();
                let mut remaining_tokens = next_rest;
                loop {
                    let (arg, new_remaining_tokens) = parse_term(remaining_tokens)?;
                    args.push(arg);
                    remaining_tokens = new_remaining_tokens;

                    let (next_token, new_remaining_tokens) = expect_any_token(remaining_tokens)?;
                    if next_token == Token::RParen {
                        return Ok((Term::Structure {
                            functor: atom,
                            arity: args.len(),
                            args,
                        }, new_remaining_tokens));
                    } else if next_token != Token::Comma {
                        return Err(ParseError::UnexpectedToken(next_token));
                    } else {
                        remaining_tokens = new_remaining_tokens;
                    }
                }
            } else {
                Ok((Term::Atom(atom), rest))
            }
        }
        Token::Variable(variable) => Ok((Term::Variable(variable), rest)),
        Token::LParen => {
            let (term, rest) = parse_term(rest)?;
            let rest = expect_token(Token::RParen, rest)?;
            Ok((term, rest))
        }
        Token::LBracket => {
            let (list_elements, rest) = parse_list_elements(rest)?;
            let rest = expect_token(Token::RBracket, rest)?;
            Ok((Term::List(list_elements), rest))
        }
        Token::Number(number) => Ok((Term::Atom(number.to_string()), rest)),
        Token::Plus => {
            let (left, rest) = parse_term(rest)?;
            let (right, rest) = parse_term(rest)?;
            Ok((Term::Structure {
                functor: "+".to_string(),
                arity: 2,
                args: vec![left, right],
            }, rest))
        }        
        _ => Err(ParseError::UnexpectedToken(token)),
    }
}

fn parse_list_elements<'a>(tokens: &'a [Token]) -> ParseResult<(Vec<Term>, &'a [Token])> {
    let mut elements = Vec::new();
    let mut remaining_tokens = tokens;

    while let Ok((term, new_remaining_tokens)) = parse_term(remaining_tokens) {
        elements.push(term);
        remaining_tokens = new_remaining_tokens;

        if let Ok(new_remaining_tokens) = expect_token(Token::Comma, remaining_tokens) {
            remaining_tokens = new_remaining_tokens;
        } else {
            break;
        }
    }
    println!("Parsed list elements: {:?}, remaining tokens: {:?}", elements, remaining_tokens);

    Ok((elements, remaining_tokens))
}

fn expect_any_token<'a>(tokens: &'a [Token]) -> ParseResult<(Token, &'a [Token])> {
    if tokens.is_empty() {
        Err(ParseError::UnexpectedEndOfInput)
    } else {
        Ok((tokens[0].clone(), &tokens[1..]))
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::parser::lexer::Token;

   
    #[test]
    fn test_parse_arithmetic_expression() {
        let input = "X is 2 + 3";
        let tokens = lexer::tokenize(input).unwrap();
        let mut token_iter = tokens.into_iter().peekable();

        let term = parse_term(&mut token_iter).unwrap();
        assert_eq!(term, Term::Variable("X".to_string()));

        let is_token = token_iter.next().unwrap();
        assert_eq!(is_token, lexer::Token::Is);

        let term = parse_term(&mut token_iter).unwrap();
        assert_eq!(
            term,
            Term::Structure(
                "add".to_string(),
                vec![
                    Term::Number(2),
                    Term::Number(3),
                ]
            )
        );

        assert!(token_iter.next().is_none());
    }
}
    
    